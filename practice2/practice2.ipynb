{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f32baf2-7c55-4bd0-b1d1-e523e1e43b81",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1ed0605a1ecd96cad894947e442e4df9",
     "grade": false,
     "grade_id": "cell-7ee9713c21fe1b06",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/upm-classes/image-understanding-2022-2023/blob/main/practice2/practice2.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee45362-7fd5-4d50-8793-a6c0ab298264",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3efd170e9d858e399b9167e413d32888",
     "grade": false,
     "grade_id": "cell-596274020aff7aca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Practice 2: Content-based image retrieval\n",
    "\n",
    "This is the second practice of image understanding in which we are going to code some of the things we have already seen during classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdf1a96-4cef-403f-a02c-475652a06dac",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "97f306477e0f4bbd52f4ef6fa66ff972",
     "grade": false,
     "grade_id": "cell-2fb10c18c61c33a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Fill with your data:\n",
    "\n",
    "- Full name 1: \n",
    "- Full name 2: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33621ac4-fbc6-4d3a-a315-e541041e65b5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "af303a7dcd03adcdb124a818537397bb",
     "grade": false,
     "grade_id": "cell-f0c1ef4f88f4f5c4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**DO NOT MODIFY (ADD, DELETE,...) ANY CELL. YOU HAVE TO WRITE YOUR CODE ONLY IN THE CELLS SPECIFIED.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb65b254-c08f-41a5-9210-696e860589ed",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7d9106c75cd704e9b45c55d17e1b9caa",
     "grade": false,
     "grade_id": "cell-805be4cc9f1fc4b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Content-based image retrieval** (CBIR) is the mechanism of retrieving images relevant to a given query from a large collection of images known as an image database, based on their semantic or visual content rather than on derived attributes or keyword descriptors prescriptively defined for them.\n",
    "\n",
    "As shown in the picture there are some basic steps involved in query and retrieval:\n",
    "\n",
    "- Feature extraction: Of course, this part involves the extraction of image characteristics, such as texture, color, etc. It could also be considered a preprocessing step to, for example, resize or improve the quality of the images.\n",
    "- Similarity measure: The similarity measurement is used to estimate the query image with the database images by similarity. The dissimilarity between the feature vector of the query image and the database images is calculated using different distance metrics. The higher the dissimilarity, the less similar the two images are. Some commonly used distances are: Euclidean distance, block distance, Minkowski distance and Mahalanobis distance.\n",
    "- Retrieve the results: The N most similar images are displayed to the user.\n",
    "\n",
    "![CBIR](https://raw.githubusercontent.com/upm-classes/image-understanding-2022-2023/main/practice2/figures/cbir_01.jpg \"CBIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a847c447-f83c-4938-bcc8-38596375cc5e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80828cf52d33af40225cf46cd995916a",
     "grade": false,
     "grade_id": "cell-fa1589f41f9c391f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download data\n",
    "! git clone https://github.com/upm-classes/image-understanding-2022-2023.git\n",
    "! mv image-understanding-2022-2023/practice2/autoencoder_STL10_0499.pt ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a88827-815f-4079-99f7-b9b850140180",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b558f69aff05d752a79a231bc2e7d917",
     "grade": false,
     "grade_id": "cell-e036b562ed74e143",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# These are the libraries that should be used. \n",
    "# NO OTHER LIBRARIES ARE ALLOWED\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import STL10\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from scipy.signal import convolve2d\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "except:\n",
    "    ! pip install torchinfo\n",
    "    from torchinfo import summary\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adca3ee9-9966-498b-ac21-e43954a363a4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ebd822093fda0ef780b254113d85091",
     "grade": false,
     "grade_id": "cell-27b8a1ce246ca861",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# assert device.type == \"cuda\", \"You need to change the runtime type to GPU\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e503d802-a6f2-49d3-999e-ba901c2df212",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07e8b1249a77b397500fc3d67e85d340",
     "grade": false,
     "grade_id": "cell-12dd2186b3a90e0d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Dataset\n",
    "\n",
    "Labels of the CIFAR10 dataset. \n",
    "\n",
    "- Images are 96x96 pixels, color.\n",
    "- 10 classes: airplane, bird, car, cat, deer, dog, horse, monkey, ship, truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5324c4e-6170-491a-9cf2-200b8a30a1aa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4bf992bb9c3a57b354e274bac05dcb1e",
     "grade": false,
     "grade_id": "cell-a71b8122cfebd966",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LABELS = {\n",
    "    0:'airplane', \n",
    "    1: 'bird',\n",
    "    2: 'car',\n",
    "    3: 'cat',\n",
    "    4: 'deer',\n",
    "    5: 'dog',\n",
    "    6: 'horse',\n",
    "    7: 'monkey',\n",
    "    8: 'ship',\n",
    "    9: 'truck'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d886c19-5bf3-4cbf-9c0f-5326be0d1963",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e764bb87fbdf505eb9f6227749d4985d",
     "grade": false,
     "grade_id": "cell-23168c480b2a74e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_data = STL10(root='STL10/images', split='train', download=True, transform=train_transform)\n",
    "test_data = STL10(root='STL10/images', split='test', download=True, transform=val_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718f3e73-b62d-4484-a8d2-3663909646dd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "45746e39ebe815ffd01f4090c98480dd",
     "grade": false,
     "grade_id": "cell-f98bfaaf90185e0d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Visualizing the first 10 images of the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b1ae04-5150-4d43-9278-b5c77b67f81f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "513b3bb8d999937f872636025b267326",
     "grade": false,
     "grade_id": "cell-50097fe3651d25e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_IMAGES = 10\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "for i in range(NUM_IMAGES):\n",
    "    im = np.rollaxis(train_data[i][0].numpy(), 0, 3)\n",
    "    ax = fig.add_subplot(2, 5, i + 1)\n",
    "    ax.imshow(im)\n",
    "    ax.set_title(LABELS[train_data[i][1]])\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e7faed-dca2-4b37-8f75-abd0ed262f37",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "776707f0d1d808ccff5bade955b71a30",
     "grade": false,
     "grade_id": "cell-b403b25add337c56",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Feature extraction phase with an autoencoder\n",
    "\n",
    "An autoencoder is a neural network that is unsupervised which means that doesn't require any labeled data. \n",
    "\n",
    "They work by compressing the input into a latent space representation and reconstructing the output from this representation:\n",
    "\n",
    "- Encoder: the part of the network that compresses the input into a latent space  representation (i.e., representation of compressed data). It can be represented by an encoding function \\\\( h=f(x) \\\\).\n",
    "- Decoder: This part aims to reconstruct the input from the latent space representation. It can be represented by a decoding function \\\\( r=g(h) \\\\).\n",
    "\n",
    "![CBIR Autoencoder](https://raw.githubusercontent.com/upm-classes/image-understanding-2022-2023/main/practice2/figures/cbir_02.jpg \"CBIR Autoencoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd1eac3-cbd0-4206-8e9d-0484a207bf3e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3a91b9ed865691eebdb6a723ce3eb3af",
     "grade": false,
     "grade_id": "cell-4248a6ea66581d78",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Autoencoder code\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_channels, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv5 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv7 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv8 = nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv9 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(4608, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(self.conv8(x))\n",
    "        x = F.relu(self.conv9(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, num_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim, 4608)\n",
    "        self.conv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.conv2 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.conv3 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.conv4 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.conv5 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.conv6 = nn.Conv2d(256, num_channels, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = x.view(x.size(0), 512, 3, 3)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, num_channels, latent_dim):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = Encoder(num_channels, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, num_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65195a35-d2ae-4be1-a8f5-595c67532781",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0dd82ba42d899154fcf0753b4946cfd1",
     "grade": false,
     "grade_id": "cell-32260b9fdc9753fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creating model\n",
    "model = AutoEncoder(num_channels=3, latent_dim=128).to(device)\n",
    "\n",
    "# Loading pretrained weights\n",
    "model.load_state_dict(torch.load('autoencoder_STL10_0499.pt', \n",
    "                                 map_location=device))\n",
    "\n",
    "summary(model, input_size=(1, 3, 96, 96))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a8fdce-d7d2-4c84-9b1d-3b9d993b10f2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d202d2eaa65b6c48a8057e65f089c7c2",
     "grade": false,
     "grade_id": "cell-96d3bff6b61d146d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Test how the autoencoder works with N random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e340e10d-756f-45a8-9e9b-ef88d2894818",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8de01235398acb554bc02df3266c841e",
     "grade": false,
     "grade_id": "cell-68cb63703c807d5e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "num_images = 5\n",
    "idx_random = np.random.choice(len(train_data), num_images)\n",
    "\n",
    "y_hat = np.array([model(torch.unsqueeze(train_data[i][0].to(device),\n",
    "                                        0)).detach().cpu().numpy() \n",
    "                                        for i in idx_random])\n",
    "\n",
    "fig = plt.figure(figsize=(4, num_images*3))\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "for i in range(num_images):\n",
    "    im1 = np.rollaxis(train_data[idx_random[i]][0].numpy(), 0, 3)\n",
    "    im1 = np.clip(im1, 0, 1)\n",
    "    ax1 = fig.add_subplot(6, 2, i * 2 + 1)\n",
    "    ax1.imshow(im1)\n",
    "    ax1.set_title(LABELS[train_data[idx_random[i]][1]])\n",
    "    ax1.axis('off')\n",
    "    im2 = np.rollaxis(np.squeeze(y_hat[i]), 0, 3)\n",
    "    im2 = np.clip(im2, 0, 1)\n",
    "    ax2 = fig.add_subplot(6, 2, i * 2 + 2)\n",
    "    ax2.imshow(im2)\n",
    "    ax2.set_title(LABELS[train_data[idx_random[i]][1]])\n",
    "    ax2.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd365dbd-1a65-4972-b05b-c53aa2a7b475",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c25361e407922712069a25e10ee83fc6",
     "grade": false,
     "grade_id": "cell-648aab0c974fff2f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Similarity calculation\n",
    "\n",
    "This step involves calculating the similarity between all the images of the database and a test image.\n",
    "\n",
    "As you can imagine this is high-demanding process (calculating all the distances), so there are different techniques that can be used to streamlite this process, such as precalculating the distances, use of distances trees.\n",
    "\n",
    "As our database is not big, we are going to use for calculating the distance an algorithm called \"k-nearest neighbors\" (k-NN). k-NN is a non-parametric supervised learning method used for classification that determines the class/label of a new sample by taking into account the k closest training examples in a dataset. When k is set to one (k = 1), then input sample is assigned to the single nearest neighbor.\n",
    "\n",
    "In our case, we are going to use the distances calculated for k-NN algorithm to retrieve the N most similar images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9326dbc1-4524-4e03-9b20-7fd56474fbdc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e83589adccb007af9c009c75920e563",
     "grade": false,
     "grade_id": "cell-1b07afd5d7fe0087",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# It takes some time to calculate the features for the train and testing sets\n",
    "\n",
    "def extract_features(partition:str) -> np.array:\n",
    "    # Here we use the encoder to return the latent features of the input images\n",
    "    if partition == 'train':\n",
    "        feats = np.array([model.encoder(torch.unsqueeze(train_data[i][0].to(device),\n",
    "                                        0)).detach().cpu().numpy() \n",
    "                                        for i in range(len(train_data))])\n",
    "    elif partition == 'test':\n",
    "        feats = np.array([model.encoder(torch.unsqueeze(test_data[i][0].to(device),\n",
    "                                        0)).detach().cpu().numpy() \n",
    "                                        for i in range(len(train_data))])\n",
    "    return np.squeeze(feats)\n",
    "\n",
    "train_feats = extract_features('train') # Train set\n",
    "test_feats = extract_features('test') # Test set\n",
    "\n",
    "print(f'Size train: {train_feats.shape}')\n",
    "print(f'Size test: {test_feats.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd710507-ccc6-4825-9dec-9c6eeae93899",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9c057fdded0bb617c35e27e80c37958c",
     "grade": false,
     "grade_id": "cell-897adc28f802d06a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##### Task 1: Implement euclidean distance (1 point)\n",
    "To measure the similarity between images, the euclidean distance between images x and y is commonly used. \n",
    "The closer to 0 the more similar x and y are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6559bf-230f-4ea2-a2c2-24e588bc6ea0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43a10fb4661817eb3ebb8085d1212408",
     "grade": false,
     "grade_id": "euclidean_distance",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Write the code for the euclidean distance\n",
    "\n",
    "def euclidean_distance(x: np.array, y: np.array) -> float:\n",
    "    \"\"\" Define the function of the euclidean distance.\n",
    "    You have to use numpy to define it. \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e4ca14-73fb-46f7-b0c1-84ed8782beb9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "915972bb5d428e2bbefc307bcdc56954",
     "grade": true,
     "grade_id": "euclidean_distance_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert np.isclose(euclidean_distance(np.array((5, 6, 1)), np.array((1, 1, 1))), 6.4031).all()\n",
    "assert np.isclose(euclidean_distance(np.array((1, 1, 1)), np.array((1, 1, 1))), 0.0).all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b5e3a8-11ae-48d6-b588-b4782bb80ae4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "953905d96439c55401751aaa84ed34fc",
     "grade": false,
     "grade_id": "cell-31b48d49410d69cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "##### Retrieve the most similar images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10422c6f-1401-4038-b58c-5a7251f61f6d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38d29e800969b317f4f2035dad0476b7",
     "grade": false,
     "grade_id": "cell-3569847224ee4225",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "IDX_SAMPLE = 500 # This corresponds to the index of the query image\n",
    "NUM_SAMPLES = 9 # Number of images to retrieve\n",
    "\n",
    "query_feats = test_feats[IDX_SAMPLE].reshape(1, -1)    \n",
    "\n",
    "# This function retreive the indexes and distances of the n neighbors most similar to the query image\n",
    "knn = KNeighborsClassifier(n_neighbors=1, metric=euclidean_distance).fit(train_feats, np.zeros((train_feats.shape[0], 1)))\n",
    "retrieved_distances, retrieved_idx = knn.kneighbors(query_feats, n_neighbors=NUM_SAMPLES, return_distance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4aafff-5113-4c25-aa15-926a3cc1facd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f763877db77a3b64173bcd7e5a3b6cf",
     "grade": false,
     "grade_id": "cell-8119103ec0ec7170",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualization of the images\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "ax = fig.add_subplot(2, 5, 1)\n",
    "\n",
    "ax.imshow(np.rollaxis(test_data[IDX_SAMPLE][0].numpy(), 0, 3))\n",
    "ax.set_title(f'Test image: {LABELS[test_data[IDX_SAMPLE][1]]}')\n",
    "ax.axis('off')\n",
    "for i in range(NUM_SAMPLES):\n",
    "    im = np.rollaxis(train_data[np.squeeze(retrieved_idx)[i]][0].numpy(), 0, 3)\n",
    "    ax = fig.add_subplot(2, 5, i + 2)\n",
    "    ax.imshow(im)\n",
    "    label = LABELS[train_data[np.squeeze(retrieved_idx)[i]][1]]\n",
    "    distance = np.squeeze(retrieved_distances)[i]\n",
    "    title = f'{label}: {distance:.4f}'\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc58875-610b-4e70-89dd-081455c5dc5d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d451cfa4b078963bca05f49acd2e5f6b",
     "grade": false,
     "grade_id": "cell-e91d0d6d2a5d463f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##### Task 2: Implement cosine distance (1 point)\n",
    "Instead of the Euclidean distance, implement a distance based on the Cosine Similarity (CS). CS is a measurement that quantifies the similarity between two or more vectors. CS is the cosine of the angle between vectors. The vectors are typically non-zero and are within an inner product space. And it is defined as follows:\n",
    " \n",
    " $$ \n",
    " d(x,y)=\\frac{x \\bullet y}{ ||x|| ||y||} \n",
    " $$\n",
    " \n",
    "where $\\bullet$ represents the dot product, and $||.||$, the norm 2.\n",
    " \n",
    "A cosine value of 0 means that the two vectors are at 90 degrees to each other (orthogonal) and have no match. The closer the cosine value to 1, the smaller the angle and the greater the match between vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4c9e16-5f91-4c2d-abf7-c96c6bd71599",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "12eb9c79aac0306f55f4543ee2d7a287",
     "grade": false,
     "grade_id": "cosine_distance",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hint: closer images to the sample should have a smaller distance\n",
    "\n",
    "def cosine_distance(x:np.array, y:np.array) -> float:\n",
    "    \"\"\" Define the cosine distance which is based on the\n",
    "    cosine similarity. You have to use numpy to define it.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b698b3d3-24c1-4aa4-82f5-a5a6161d85f4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c1f6a47476cc7673342803b1b7a31998",
     "grade": true,
     "grade_id": "cosine_distance_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert np.isclose(cosine_distance(np.array((1, 0, 0)), np.array((1, 1, 1))), 0.42264, rtol=1e-03, atol=1e-05).all()\n",
    "assert np.isclose(cosine_distance(np.array((1, 1, 1)), np.array((1, 1, 1))), 0.0).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911b3759-d96c-4cba-9c23-9cf45c15f44f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6dbc67c8d2bf078b4a26b7e00da9ba5c",
     "grade": false,
     "grade_id": "cell-e86018e787fdc01b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IDX_SAMPLE = 500 # This corresponds to the index of the query image\n",
    "NUM_SAMPLES = 9 # Number of images to retrieve\n",
    "\n",
    "query_feats = test_feats[IDX_SAMPLE].reshape(1, -1)    \n",
    "\n",
    "# This function retreive the indexes and distances of the n neighbors most similar to the query image\n",
    "knn = KNeighborsClassifier(n_neighbors=1, metric=cosine_distance).fit(train_feats, np.zeros((train_feats.shape[0], 1)))\n",
    "retrieved_distances, retrieved_idx = knn.kneighbors(query_feats, n_neighbors=NUM_SAMPLES, return_distance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6572bb9a-7184-4daf-8309-3afa9d318cd2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25e482d9be22515b850b9a77612e9fae",
     "grade": false,
     "grade_id": "cell-2fa611e4e4e1203e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualization of the images\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "ax = fig.add_subplot(2, 5, 1)\n",
    "\n",
    "ax.imshow(np.rollaxis(test_data[IDX_SAMPLE][0].numpy(), 0, 3))\n",
    "ax.set_title(f'Test image: {LABELS[test_data[IDX_SAMPLE][1]]}')\n",
    "ax.axis('off')\n",
    "for i in range(NUM_SAMPLES):\n",
    "    im = np.rollaxis(train_data[np.squeeze(retrieved_idx)[i]][0].numpy(), 0, 3)\n",
    "    ax = fig.add_subplot(2, 5, i + 2)\n",
    "    ax.imshow(im)\n",
    "    label = LABELS[train_data[np.squeeze(retrieved_idx)[i]][1]]\n",
    "    distance = np.squeeze(retrieved_distances)[i]\n",
    "    title = f'{label}: {distance:.4f}'\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aa9d73-1d29-4722-ab06-4aa89456d091",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3d3224779cf4adbe8c1466c077c4134d",
     "grade": false,
     "grade_id": "cell-2f3025ee2eb76297",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Using raw pixels as features\n",
    "\n",
    "Another type of features that we can use are the pixels of the image. For this with need to convert each image into a vector. \n",
    "\n",
    "##### Task 3: Implement a funtion to convert all images into a matrix (1 point). \n",
    "Hint: the shape of the output should be: [N, 96x96x3], where N is the number of images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bcdb24-ca63-4af5-a8fc-4b38fa6eb0d2",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d37c4fd4e35355efd6b46adefaf1f33",
     "grade": false,
     "grade_id": "features_raw",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_features_raw(images:np.array) -> np.array:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3bedee-989d-4b0d-b122-25f7a3f9b454",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b0975d2dbc2e6c0f53ea3b5c32c8fc7",
     "grade": false,
     "grade_id": "cell-4c82e8e1bd3695f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_images = np.array([train_data[i][0].detach().cpu().numpy() for i in range(len(train_data))])\n",
    "train_images = np.rollaxis(train_images, 1, 4)\n",
    "test_images = np.array([test_data[i][0].detach().cpu().numpy() for i in range(len(train_data))])\n",
    "test_images = np.rollaxis(test_images, 1, 4)\n",
    "\n",
    "train_feats_raw = extract_features_raw(train_images) # Train set\n",
    "test_feats_raw = extract_features_raw(test_images) # Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d81871-adb4-4418-9908-54664b798be8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "713498b87d58bc2541516e029b6afd3d",
     "grade": true,
     "grade_id": "features_raw_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert (train_feats_raw.shape == np.array([5000, 96 * 96 * 3])).all()\n",
    "assert (test_feats_raw.shape == np.array([5000, 96 * 96 * 3])).all()\n",
    "\n",
    "x = np.reshape(np.array([range(27648)]), (1, 96, 96, 3))\n",
    "assert extract_features_raw(x)[0][1] == 1\n",
    "assert extract_features_raw(x)[0][9218] == 9218\n",
    "assert extract_features_raw(x)[0][18432] == 18432\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1c1337-94b0-45fc-a9d0-8ae784ece662",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e3502292bff9f735614cfce508e6d011",
     "grade": false,
     "grade_id": "cell-3d612016296bc5aa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Show the results with raw pixels using the euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb2dc1d-0a97-4eda-b8c0-ffe60548e556",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b5eccc301043142098d9c7482d465a0",
     "grade": false,
     "grade_id": "cell-8162e7b276056b45",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "IDX_SAMPLE = 500 # This corresponds to the index of the query image\n",
    "NUM_SAMPLES = 9 # Number of images to retrieve\n",
    "\n",
    "query_feats = test_feats_raw[IDX_SAMPLE].reshape(1, -1)    \n",
    "\n",
    "# This function retreive the indexes and distances of the n neighbors most similar to the query image\n",
    "knn = KNeighborsClassifier(n_neighbors=1, metric=euclidean_distance).fit(train_feats_raw, np.zeros((train_feats_raw.shape[0], 1)))\n",
    "retrieved_distances, retrieved_idx = knn.kneighbors(query_feats, n_neighbors=NUM_SAMPLES, return_distance=True)\n",
    "\n",
    "# Visualization of the images\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "ax = fig.add_subplot(2, 5, 1)\n",
    "\n",
    "ax.imshow(np.rollaxis(test_data[IDX_SAMPLE][0].numpy(), 0, 3))\n",
    "ax.set_title(f'Test image: {LABELS[test_data[IDX_SAMPLE][1]]}')\n",
    "ax.axis('off')\n",
    "for i in range(NUM_SAMPLES):\n",
    "    im = np.rollaxis(train_data[np.squeeze(retrieved_idx)[i]][0].numpy(), 0, 3)\n",
    "    ax = fig.add_subplot(2, 5, i + 2)\n",
    "    ax.imshow(im)\n",
    "    label = LABELS[train_data[np.squeeze(retrieved_idx)[i]][1]]\n",
    "    distance = np.squeeze(retrieved_distances)[i]\n",
    "    title = f'{label}: {distance:.4f}'\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d39d57-2268-4221-9fd4-1f1af2cc336a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e25664f69c2dcf31b1f16d692f50acc3",
     "grade": false,
     "grade_id": "cell-7187290fdd4e9e12",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Show the results with raw pixels using the cosine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56221bb9-8f95-4aaa-95cf-5a3a9c966f94",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "74cd36af2620900f980227cad05c7d5c",
     "grade": false,
     "grade_id": "cell-62068ba4d594691f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "IDX_SAMPLE = 500 # This corresponds to the index of the query image\n",
    "NUM_SAMPLES = 9 # Number of images to retrieve\n",
    "\n",
    "query_feats = test_feats_raw[IDX_SAMPLE].reshape(1, -1)    \n",
    "\n",
    "# This function retreive the indexes and distances of the n neighbors most similar to the query image\n",
    "knn = KNeighborsClassifier(n_neighbors=1, metric=cosine_distance).fit(train_feats_raw, np.zeros((train_feats_raw.shape[0], 1)))\n",
    "retrieved_distances, retrieved_idx = knn.kneighbors(query_feats, n_neighbors=NUM_SAMPLES, return_distance=True)\n",
    "\n",
    "# Visualization of the images\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "ax = fig.add_subplot(2, 5, 1)\n",
    "\n",
    "ax.imshow(np.rollaxis(test_data[IDX_SAMPLE][0].numpy(), 0, 3))\n",
    "ax.set_title(f'Test image: {LABELS[test_data[IDX_SAMPLE][1]]}')\n",
    "ax.axis('off')\n",
    "for i in range(NUM_SAMPLES):\n",
    "    im = np.rollaxis(train_data[np.squeeze(retrieved_idx)[i]][0].numpy(), 0, 3)\n",
    "    ax = fig.add_subplot(2, 5, i + 2)\n",
    "    ax.imshow(im)\n",
    "    label = LABELS[train_data[np.squeeze(retrieved_idx)[i]][1]]\n",
    "    distance = np.squeeze(retrieved_distances)[i]\n",
    "    title = f'{label}: {distance:.4f}'\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9196d64e-e45d-4202-826c-f851edd78296",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eda5fe9c090b5ff537e0d30a0bc98098",
     "grade": false,
     "grade_id": "cell-0f51ae1bf899a4b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Using features extracted by filtering\n",
    "\n",
    "Usin the soble function implemented in the previous practice we are going to extract the features of the images. \n",
    "\n",
    "##### Task 4: Implement a funtion to extract the features of the a set of images (3 points).\n",
    "Steps:\n",
    "1. Convert each image into a grayscale version by calculating the average among channels.\n",
    "2. From each grayscale image apply the sobel filtering.\n",
    "3. Convert each filtered image into a vector.\n",
    "\n",
    "Hint: the shape of the output should be: [N, 96x96x1], where N is the number of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93a31d1-517d-49ad-88df-be8ce0df10b6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9be51ee4926a89329fb29c9513e75a41",
     "grade": false,
     "grade_id": "sobel_features",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_features_sobel(images:np.array) -> np.array:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081dcd92-6944-4e19-9642-a97256f4d886",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ade6856b1483ea75f23f56db0ba6794c",
     "grade": false,
     "grade_id": "cell-ae2ad7e7e421f9c0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_feats_sobel = extract_features_sobel(train_images) # Train set\n",
    "test_feats_sobel = extract_features_sobel(test_images) # Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03f0d54-ddba-4650-92dc-5af717944580",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3c2846acd8cef0e7cadbfefd0b1811b",
     "grade": true,
     "grade_id": "sobel_features_test",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert (train_feats_sobel.shape == np.array([5000, 96*96])).all()\n",
    "assert (test_feats_sobel.shape == np.array([5000, 96*96])).all()\n",
    "assert (np.isclose(train_feats_sobel[1, 1:9], np.array([0.08000583, 0.30175989, 0.19362304, 0.20109494, 0.25172131, 0.0282184 , 0.2295969 , 0.13676229]))).all()\n",
    "assert (np.isclose(test_feats_sobel[1, 1:9], np.array([0.26003544, 0.0942809 , 0.05918552, 0.11209864, 0.08725918, 0.08308626, 0.14767192, 0.073992]))).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd1886b-7dfc-403d-8f4f-089cf6767fb5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6a424823f82c2643cd8a7682a9b6dffb",
     "grade": false,
     "grade_id": "cell-d937486d98563577",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Show the results with raw pixels using the euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b651c93-82b7-4498-ae31-c67dc8cecc47",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f4f7e12d3f0fb207b85d6c588ceef57",
     "grade": false,
     "grade_id": "cell-52e8d4b03094321a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IDX_SAMPLE = 500 # This corresponds to the index of the query image\n",
    "NUM_SAMPLES = 9 # Number of images to retrieve\n",
    "\n",
    "query_feats = test_feats_sobel[IDX_SAMPLE].reshape(1, -1)    \n",
    "\n",
    "# This function retreive the indexes and distances of the n neighbors most similar to the query image\n",
    "knn = KNeighborsClassifier(n_neighbors=1, metric=euclidean_distance).fit(train_feats_sobel, np.zeros((train_feats_sobel.shape[0], 1)))\n",
    "retrieved_distances, retrieved_idx = knn.kneighbors(query_feats, n_neighbors=NUM_SAMPLES, return_distance=True)\n",
    "\n",
    "# Visualization of the images\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "ax = fig.add_subplot(2, 5, 1)\n",
    "\n",
    "ax.imshow(np.rollaxis(test_data[IDX_SAMPLE][0].numpy(), 0, 3))\n",
    "ax.set_title(f'Test image: {LABELS[test_data[IDX_SAMPLE][1]]}')\n",
    "ax.axis('off')\n",
    "for i in range(NUM_SAMPLES):\n",
    "    im = np.rollaxis(train_data[np.squeeze(retrieved_idx)[i]][0].numpy(), 0, 3)\n",
    "    ax = fig.add_subplot(2, 5, i + 2)\n",
    "    ax.imshow(im)\n",
    "    label = LABELS[train_data[np.squeeze(retrieved_idx)[i]][1]]\n",
    "    distance = np.squeeze(retrieved_distances)[i]\n",
    "    title = f'{label}: {distance:.4f}'\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf5ad98-2668-48f6-ba29-ccb4a336cad3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cdb37b36b22c77104b7fb947c6a454af",
     "grade": false,
     "grade_id": "cell-82decf4b556961ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Show the results with raw pixels using the cosine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6321e2e5-d946-496f-b387-17b7e23fe8d4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2014199361404c3d2e1b3137b155f7c1",
     "grade": false,
     "grade_id": "cell-ae0a36ef1c9cd1c6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IDX_SAMPLE = 500 # This corresponds to the index of the query image\n",
    "NUM_SAMPLES = 9 # Number of images to retrieve\n",
    "\n",
    "query_feats = test_feats_sobel[IDX_SAMPLE].reshape(1, -1)    \n",
    "\n",
    "# This function retreive the indexes and distances of the n neighbors most similar to the query image\n",
    "knn = KNeighborsClassifier(n_neighbors=1, metric=cosine_distance).fit(train_feats_sobel, np.zeros((train_feats_sobel.shape[0], 1)))\n",
    "retrieved_distances, retrieved_idx = knn.kneighbors(query_feats, n_neighbors=NUM_SAMPLES, return_distance=True)\n",
    "\n",
    "# Visualization of the images\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "ax = fig.add_subplot(2, 5, 1)\n",
    "\n",
    "ax.imshow(np.rollaxis(test_data[IDX_SAMPLE][0].numpy(), 0, 3))\n",
    "ax.set_title(f'Test image: {LABELS[test_data[IDX_SAMPLE][1]]}')\n",
    "ax.axis('off')\n",
    "for i in range(NUM_SAMPLES):\n",
    "    im = np.rollaxis(train_data[np.squeeze(retrieved_idx)[i]][0].numpy(), 0, 3)\n",
    "    ax = fig.add_subplot(2, 5, i + 2)\n",
    "    ax.imshow(im)\n",
    "    label = LABELS[train_data[np.squeeze(retrieved_idx)[i]][1]]\n",
    "    distance = np.squeeze(retrieved_distances)[i]\n",
    "    title = f'{label}: {distance:.4f}'\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a52b2ae-138b-48b6-b81d-68aaa37f4316",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3d4f95091acee39ec0ad16b0f77fabeb",
     "grade": false,
     "grade_id": "cell-c34c7d9b7868217c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##### Task 5: Answer the following questions (4 points):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d095f69-3336-4233-9c1b-7a667ab5eaa0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "02a85d87e02012cf79016e06fa51887b",
     "grade": false,
     "grade_id": "question1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "1. What considerations did you have when implementing the distance function based on cosine similarity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dd0a8a-c06b-426b-814e-c2166b888656",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "670e9760f426751365854e320bc1e0d5",
     "grade": true,
     "grade_id": "answer1",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df19f1c-7706-4178-84e5-ebd0b98778e8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b676783b0ee670b22634952e3f4f194",
     "grade": false,
     "grade_id": "question2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "2. What differences do you find between the different experiments performed? Discuss the results obtained in terms of how they are affected by the characteristics extracted and the distances used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8623ae-a426-41b9-9b10-9e7cfa4a1e15",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c890314bf903ef6516d5d5835300db06",
     "grade": true,
     "grade_id": "cell-55153772b7bc3413",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
